{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Practice Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/lilymartin/DEVOPS/testing_python_docker/app/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns = ['Cabin', 'Name', 'Ticket']):\n",
    "    \"\"\"\n",
    "    remove unwanted columns\n",
    "    \"\"\"\n",
    "    cols = [x for x in list(df.columns) if x not in columns]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nan(df):\n",
    "    \"\"\"\n",
    "    Checking df for any rows with NaN\n",
    "    \"\"\"\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_buckets(df):\n",
    "    \"\"\"\n",
    "    Sort age column into age buckets\n",
    "    \"\"\"\n",
    "    age_col = 'Age'\n",
    "    df.loc[df[age_col] <= 17, 'AgeBuckets'] = '0_17'\n",
    "    df.loc[(df[age_col] > 17) & (df[age_col] <= 24), 'AgeBuckets'] = '18_24'\n",
    "    df.loc[(df[age_col] >= 25) & (df[age_col] <= 34), 'AgeBuckets'] = '25_34'\n",
    "    df.loc[(df[age_col] >= 35) & (df[age_col] <= 44), 'AgeBuckets'] = '35_44'\n",
    "    df.loc[(df[age_col] >= 45) & (df[age_col] <= 54), 'AgeBuckets'] = '45_54'\n",
    "    df.loc[(df[age_col] >= 55) & (df[age_col] <= 64), 'AgeBuckets'] = '55_64'\n",
    "    df.loc[(df[age_col] >= 65) & (df[age_col] <= 74), 'AgeBuckets'] = '65_74'\n",
    "    df.loc[(df[age_col] >= 75), 'AgeBuckets'] = '75_plus'\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_buckets(df):\n",
    "    \"\"\"\n",
    "    Sort fares into buckets\n",
    "    \"\"\"\n",
    "    fare_col = 'Fare'\n",
    "    df.loc[df[fare_col] <= 9, 'FareBucket'] = '0_9'\n",
    "    df.loc[(df[fare_col] > 10) & (df[fare_col] <= 16), 'FareBucket'] = '10_16'\n",
    "    df.loc[(df[fare_col] >= 17) & (df[fare_col] <= 33), 'FareBucket'] = '17_33'\n",
    "    df.loc[(df[fare_col] >= 34), 'FareBucket'] = '34_plus'\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encoding(df):\n",
    "    \"\"\"\n",
    "    Hot encoding spefic columns \n",
    "    \"\"\"\n",
    "    cols = [x for x in list(df.columns) if x in ['Sex', 'Embarked', 'AgeBuckets', 'FareBucket']]\n",
    "    \n",
    "    for x in cols: \n",
    "        dummies = pd.get_dummies(df[x], x)\n",
    "        df = pd.concat([df.drop(x, axis=1), dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning \n",
    "df = pd.read_csv('/Users/lilymartin/DEVOPS/testing_python_docker/app/data/train.csv')\n",
    "df = remove_columns(df, ['Cabin', 'Name', 'Ticket'])\n",
    "df = check_for_nan(df)\n",
    "df = age_buckets(df)\n",
    "df = fare_buckets(df)\n",
    "df = hot_encoding(df)\n",
    "df = remove_columns(df, ['Age', 'Fare', 'PassengerId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=20, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[['Pclass', 'SibSp', 'Parch', 'Sex_female', 'Sex_male',\n",
    "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'AgeBuckets_0_17',\n",
    "       'AgeBuckets_18_24', 'AgeBuckets_25_34', 'AgeBuckets_35_44',\n",
    "       'AgeBuckets_45_54', 'AgeBuckets_55_64', 'AgeBuckets_65_74',\n",
    "       'AgeBuckets_75_plus', 'FareBucket_0_9', 'FareBucket_10_16',\n",
    "       'FareBucket_17_33', 'FareBucket_34_plus']])\n",
    "Y = np.array(df[['Survived']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.6851 - accuracy: 0.5787\n",
      "Epoch 2/150\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.6030 - accuracy: 0.6784\n",
      "Epoch 3/150\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.5632 - accuracy: 0.7289\n",
      "Epoch 4/150\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.5348 - accuracy: 0.7725\n",
      "Epoch 5/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7837\n",
      "Epoch 6/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7823\n",
      "Epoch 7/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7851\n",
      "Epoch 8/150\n",
      "72/72 [==============================] - 0s 945us/step - loss: 0.4748 - accuracy: 0.7865\n",
      "Epoch 9/150\n",
      "72/72 [==============================] - 0s 988us/step - loss: 0.4674 - accuracy: 0.7823\n",
      "Epoch 10/150\n",
      "72/72 [==============================] - 0s 967us/step - loss: 0.4607 - accuracy: 0.7921\n",
      "Epoch 11/150\n",
      "72/72 [==============================] - 0s 964us/step - loss: 0.4596 - accuracy: 0.7809\n",
      "Epoch 12/150\n",
      "72/72 [==============================] - 0s 971us/step - loss: 0.4520 - accuracy: 0.7921\n",
      "Epoch 13/150\n",
      "72/72 [==============================] - 0s 999us/step - loss: 0.4491 - accuracy: 0.7907\n",
      "Epoch 14/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7978\n",
      "Epoch 15/150\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.4490 - accuracy: 0.7893\n",
      "Epoch 16/150\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.4393 - accuracy: 0.8020\n",
      "Epoch 17/150\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.4360 - accuracy: 0.7963\n",
      "Epoch 18/150\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.4324 - accuracy: 0.8034\n",
      "Epoch 19/150\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.4294 - accuracy: 0.7992\n",
      "Epoch 20/150\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.4289 - accuracy: 0.8048\n",
      "Epoch 21/150\n",
      "72/72 [==============================] - 0s 862us/step - loss: 0.4241 - accuracy: 0.8034\n",
      "Epoch 22/150\n",
      "72/72 [==============================] - 0s 923us/step - loss: 0.4222 - accuracy: 0.8076\n",
      "Epoch 23/150\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.4219 - accuracy: 0.8132\n",
      "Epoch 24/150\n",
      "72/72 [==============================] - 0s 994us/step - loss: 0.4189 - accuracy: 0.8118\n",
      "Epoch 25/150\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.4192 - accuracy: 0.8062\n",
      "Epoch 26/150\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.4158 - accuracy: 0.8188\n",
      "Epoch 27/150\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.4159 - accuracy: 0.8160\n",
      "Epoch 28/150\n",
      "72/72 [==============================] - 0s 889us/step - loss: 0.4107 - accuracy: 0.8244\n",
      "Epoch 29/150\n",
      "72/72 [==============================] - 0s 905us/step - loss: 0.4091 - accuracy: 0.8188\n",
      "Epoch 30/150\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.4117 - accuracy: 0.8287\n",
      "Epoch 31/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8216\n",
      "Epoch 32/150\n",
      "72/72 [==============================] - 0s 935us/step - loss: 0.4070 - accuracy: 0.8315\n",
      "Epoch 33/150\n",
      "72/72 [==============================] - 0s 889us/step - loss: 0.4038 - accuracy: 0.8230\n",
      "Epoch 34/150\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.4019 - accuracy: 0.8315\n",
      "Epoch 35/150\n",
      "72/72 [==============================] - 0s 920us/step - loss: 0.4076 - accuracy: 0.8188\n",
      "Epoch 36/150\n",
      "72/72 [==============================] - 0s 852us/step - loss: 0.4005 - accuracy: 0.8329\n",
      "Epoch 37/150\n",
      "72/72 [==============================] - 0s 853us/step - loss: 0.3969 - accuracy: 0.8329\n",
      "Epoch 38/150\n",
      "72/72 [==============================] - 0s 891us/step - loss: 0.3965 - accuracy: 0.8399\n",
      "Epoch 39/150\n",
      "72/72 [==============================] - 0s 870us/step - loss: 0.3953 - accuracy: 0.8385\n",
      "Epoch 40/150\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.3898 - accuracy: 0.8385\n",
      "Epoch 41/150\n",
      "72/72 [==============================] - 0s 933us/step - loss: 0.3929 - accuracy: 0.8357\n",
      "Epoch 42/150\n",
      "72/72 [==============================] - 0s 987us/step - loss: 0.3899 - accuracy: 0.8357\n",
      "Epoch 43/150\n",
      "72/72 [==============================] - 0s 937us/step - loss: 0.3871 - accuracy: 0.8455\n",
      "Epoch 44/150\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.3867 - accuracy: 0.8427\n",
      "Epoch 45/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8413\n",
      "Epoch 46/150\n",
      "72/72 [==============================] - 0s 999us/step - loss: 0.3835 - accuracy: 0.8455\n",
      "Epoch 47/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8441\n",
      "Epoch 48/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8385\n",
      "Epoch 49/150\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.3827 - accuracy: 0.8427\n",
      "Epoch 50/150\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.3779 - accuracy: 0.8441\n",
      "Epoch 51/150\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.3809 - accuracy: 0.8441\n",
      "Epoch 52/150\n",
      "72/72 [==============================] - 0s 907us/step - loss: 0.3764 - accuracy: 0.8455\n",
      "Epoch 53/150\n",
      "72/72 [==============================] - 0s 923us/step - loss: 0.3753 - accuracy: 0.8469\n",
      "Epoch 54/150\n",
      "72/72 [==============================] - 0s 977us/step - loss: 0.3729 - accuracy: 0.8483\n",
      "Epoch 55/150\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3724 - accuracy: 0.8539\n",
      "Epoch 56/150\n",
      "72/72 [==============================] - 0s 998us/step - loss: 0.3758 - accuracy: 0.8455\n",
      "Epoch 57/150\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.3701 - accuracy: 0.8525\n",
      "Epoch 58/150\n",
      "72/72 [==============================] - 0s 900us/step - loss: 0.3687 - accuracy: 0.8553\n",
      "Epoch 59/150\n",
      "72/72 [==============================] - 0s 939us/step - loss: 0.3686 - accuracy: 0.8483\n",
      "Epoch 60/150\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.3670 - accuracy: 0.8525\n",
      "Epoch 61/150\n",
      "72/72 [==============================] - 0s 894us/step - loss: 0.3675 - accuracy: 0.8553\n",
      "Epoch 62/150\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.3653 - accuracy: 0.8567\n",
      "Epoch 63/150\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.3643 - accuracy: 0.8497\n",
      "Epoch 64/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8539\n",
      "Epoch 65/150\n",
      "72/72 [==============================] - 0s 984us/step - loss: 0.3628 - accuracy: 0.8581\n",
      "Epoch 66/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8511\n",
      "Epoch 67/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8525\n",
      "Epoch 68/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8553\n",
      "Epoch 69/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8567\n",
      "Epoch 70/150\n",
      "72/72 [==============================] - 0s 945us/step - loss: 0.3568 - accuracy: 0.8539\n",
      "Epoch 71/150\n",
      "72/72 [==============================] - 0s 898us/step - loss: 0.3574 - accuracy: 0.8511\n",
      "Epoch 72/150\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.3571 - accuracy: 0.8581\n",
      "Epoch 73/150\n",
      "72/72 [==============================] - 0s 928us/step - loss: 0.3554 - accuracy: 0.8553\n",
      "Epoch 74/150\n",
      "72/72 [==============================] - 0s 900us/step - loss: 0.3524 - accuracy: 0.8539\n",
      "Epoch 75/150\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.3517 - accuracy: 0.8610\n",
      "Epoch 76/150\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.3539 - accuracy: 0.8553\n",
      "Epoch 77/150\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.3551 - accuracy: 0.8553\n",
      "Epoch 78/150\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.3515 - accuracy: 0.8567\n",
      "Epoch 79/150\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.3506 - accuracy: 0.8567\n",
      "Epoch 80/150\n",
      "72/72 [==============================] - 0s 941us/step - loss: 0.3483 - accuracy: 0.8511\n",
      "Epoch 81/150\n",
      "72/72 [==============================] - 0s 893us/step - loss: 0.3507 - accuracy: 0.8581\n",
      "Epoch 82/150\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.3537 - accuracy: 0.8553\n",
      "Epoch 83/150\n",
      "72/72 [==============================] - 0s 934us/step - loss: 0.3477 - accuracy: 0.8610\n",
      "Epoch 84/150\n",
      "72/72 [==============================] - 0s 999us/step - loss: 0.3465 - accuracy: 0.8567\n",
      "Epoch 85/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8596\n",
      "Epoch 86/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8567\n",
      "Epoch 87/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8581\n",
      "Epoch 88/150\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.3460 - accuracy: 0.8553\n",
      "Epoch 89/150\n",
      "72/72 [==============================] - 0s 973us/step - loss: 0.3427 - accuracy: 0.8511\n",
      "Epoch 90/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8567\n",
      "Epoch 91/150\n",
      "72/72 [==============================] - 0s 960us/step - loss: 0.3408 - accuracy: 0.8596\n",
      "Epoch 92/150\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3406 - accuracy: 0.8624\n",
      "Epoch 93/150\n",
      "72/72 [==============================] - 0s 923us/step - loss: 0.3403 - accuracy: 0.8610\n",
      "Epoch 94/150\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.3415 - accuracy: 0.8567\n",
      "Epoch 95/150\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.3384 - accuracy: 0.8581\n",
      "Epoch 96/150\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3382 - accuracy: 0.8567\n",
      "Epoch 97/150\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.3377 - accuracy: 0.8610\n",
      "Epoch 98/150\n",
      "72/72 [==============================] - 0s 928us/step - loss: 0.3359 - accuracy: 0.8581\n",
      "Epoch 99/150\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.3400 - accuracy: 0.8596\n",
      "Epoch 100/150\n",
      "72/72 [==============================] - 0s 882us/step - loss: 0.3358 - accuracy: 0.8610\n",
      "Epoch 101/150\n",
      "72/72 [==============================] - 0s 871us/step - loss: 0.3362 - accuracy: 0.8567\n",
      "Epoch 102/150\n",
      "72/72 [==============================] - 0s 893us/step - loss: 0.3322 - accuracy: 0.8666\n",
      "Epoch 103/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8553\n",
      "Epoch 104/150\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.3338 - accuracy: 0.8624\n",
      "Epoch 105/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8610\n",
      "Epoch 106/150\n",
      "72/72 [==============================] - 0s 934us/step - loss: 0.3326 - accuracy: 0.8596\n",
      "Epoch 107/150\n",
      "72/72 [==============================] - 0s 940us/step - loss: 0.3327 - accuracy: 0.8624\n",
      "Epoch 108/150\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.3329 - accuracy: 0.8553\n",
      "Epoch 109/150\n",
      "72/72 [==============================] - 0s 908us/step - loss: 0.3308 - accuracy: 0.8567\n",
      "Epoch 110/150\n",
      "72/72 [==============================] - 0s 890us/step - loss: 0.3291 - accuracy: 0.8610\n",
      "Epoch 111/150\n",
      "72/72 [==============================] - 0s 933us/step - loss: 0.3307 - accuracy: 0.8638\n",
      "Epoch 112/150\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.3315 - accuracy: 0.8624\n",
      "Epoch 113/150\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.3314 - accuracy: 0.8624\n",
      "Epoch 114/150\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.3290 - accuracy: 0.8596\n",
      "Epoch 115/150\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.3277 - accuracy: 0.8581\n",
      "Epoch 116/150\n",
      "72/72 [==============================] - 0s 917us/step - loss: 0.3296 - accuracy: 0.8680\n",
      "Epoch 117/150\n",
      "72/72 [==============================] - 0s 889us/step - loss: 0.3247 - accuracy: 0.8610\n",
      "Epoch 118/150\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.3268 - accuracy: 0.8581\n",
      "Epoch 119/150\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.3253 - accuracy: 0.8722\n",
      "Epoch 120/150\n",
      "72/72 [==============================] - 0s 963us/step - loss: 0.3239 - accuracy: 0.8666\n",
      "Epoch 121/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8581\n",
      "Epoch 122/150\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.3254 - accuracy: 0.8652\n",
      "Epoch 123/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8638\n",
      "Epoch 124/150\n",
      "72/72 [==============================] - 0s 963us/step - loss: 0.3270 - accuracy: 0.8596\n",
      "Epoch 125/150\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.3263 - accuracy: 0.8652\n",
      "Epoch 126/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8567\n",
      "Epoch 127/150\n",
      "72/72 [==============================] - 0s 930us/step - loss: 0.3220 - accuracy: 0.8581\n",
      "Epoch 128/150\n",
      "72/72 [==============================] - 0s 929us/step - loss: 0.3248 - accuracy: 0.8666\n",
      "Epoch 129/150\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.3251 - accuracy: 0.8610\n",
      "Epoch 130/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8638\n",
      "Epoch 131/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8610\n",
      "Epoch 132/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8666\n",
      "Epoch 133/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8638\n",
      "Epoch 134/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8610\n",
      "Epoch 135/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8708\n",
      "Epoch 136/150\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.3196 - accuracy: 0.8666\n",
      "Epoch 137/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3155 - accuracy: 0.8736\n",
      "Epoch 138/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8624\n",
      "Epoch 139/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8638\n",
      "Epoch 140/150\n",
      "72/72 [==============================] - 0s 948us/step - loss: 0.3157 - accuracy: 0.8736\n",
      "Epoch 141/150\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.3182 - accuracy: 0.8596\n",
      "Epoch 142/150\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.3226 - accuracy: 0.8610\n",
      "Epoch 143/150\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.3193 - accuracy: 0.8567\n",
      "Epoch 144/150\n",
      "72/72 [==============================] - 0s 933us/step - loss: 0.3174 - accuracy: 0.8581\n",
      "Epoch 145/150\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.3163 - accuracy: 0.8708\n",
      "Epoch 146/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8638\n",
      "Epoch 147/150\n",
      "72/72 [==============================] - 0s 891us/step - loss: 0.3164 - accuracy: 0.8666\n",
      "Epoch 148/150\n",
      "72/72 [==============================] - 0s 977us/step - loss: 0.3161 - accuracy: 0.8666\n",
      "Epoch 149/150\n",
      "72/72 [==============================] - 0s 968us/step - loss: 0.3155 - accuracy: 0.8680\n",
      "Epoch 150/150\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.3136 - accuracy: 0.8680\n",
      "23/23 [==============================] - 0s 654us/step - loss: 0.3153 - accuracy: 0.8652\n",
      "Accuracy: 86.52\n"
     ]
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, Y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/lilymartin/DEVOPS/testing_python_docker/app/model/20200823_titantic_m1.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
