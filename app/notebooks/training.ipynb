{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Practice Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/lilymartin/DEVOPS/testing_python_docker/app/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns = ['Cabin', 'Name', 'Ticket']):\n",
    "    \"\"\"\n",
    "    remove unwanted columns\n",
    "    \"\"\"\n",
    "    cols = [x for x in list(df.columns) if x not in columns]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nan(df):\n",
    "    \"\"\"\n",
    "    Checking df for any rows with NaN\n",
    "    \"\"\"\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_buckets(df):\n",
    "    \"\"\"\n",
    "    Sort age column into age buckets\n",
    "    \"\"\"\n",
    "    age_col = 'Age'\n",
    "    df.loc[df[age_col] <= 17, 'AgeBuckets'] = '0_17'\n",
    "    df.loc[(df[age_col] > 17) & (df[age_col] <= 24), 'AgeBuckets'] = '18_24'\n",
    "    df.loc[(df[age_col] >= 25) & (df[age_col] <= 34), 'AgeBuckets'] = '25_34'\n",
    "    df.loc[(df[age_col] >= 35) & (df[age_col] <= 44), 'AgeBuckets'] = '35_44'\n",
    "    df.loc[(df[age_col] >= 45) & (df[age_col] <= 54), 'AgeBuckets'] = '45_54'\n",
    "    df.loc[(df[age_col] >= 55) & (df[age_col] <= 64), 'AgeBuckets'] = '55_64'\n",
    "    df.loc[(df[age_col] >= 65) & (df[age_col] <= 74), 'AgeBuckets'] = '65_74'\n",
    "    df.loc[(df[age_col] >= 75), 'AgeBuckets'] = '75_plus'\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_buckets(df):\n",
    "    \"\"\"\n",
    "    Sort fares into buckets\n",
    "    \"\"\"\n",
    "    fare_col = 'Fare'\n",
    "    df.loc[df[fare_col] <= 9, 'FareBucket'] = '0_9'\n",
    "    df.loc[(df[fare_col] > 10) & (df[fare_col] <= 16), 'FareBucket'] = '10_16'\n",
    "    df.loc[(df[fare_col] >= 17) & (df[fare_col] <= 33), 'FareBucket'] = '17_33'\n",
    "    df.loc[(df[fare_col] >= 34), 'FareBucket'] = '34_plus'\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encoding(df):\n",
    "    \"\"\"\n",
    "    Hot encoding spefic columns \n",
    "    \"\"\"\n",
    "    cols = [x for x in list(df.columns) if x in ['Sex', 'Embarked', 'AgeBuckets', 'FareBucket']]\n",
    "    \n",
    "    for x in cols: \n",
    "        dummies = pd.get_dummies(df[x], x)\n",
    "        df = pd.concat([df.drop(x, axis=1), dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning \n",
    "df = pd.read_csv('/Users/lilymartin/DEVOPS/testing_python_docker/app/data/train.csv')\n",
    "df = remove_columns(df, ['Cabin', 'Name', 'Ticket'])\n",
    "df = check_for_nan(df)\n",
    "df = age_buckets(df)\n",
    "df = hot_encoding(df)\n",
    "df = remove_columns(df, ['Age', 'Fare', 'PassengerId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>AgeBuckets_0_17</th>\n",
       "      <th>AgeBuckets_18_24</th>\n",
       "      <th>AgeBuckets_25_34</th>\n",
       "      <th>AgeBuckets_35_44</th>\n",
       "      <th>AgeBuckets_45_54</th>\n",
       "      <th>AgeBuckets_55_64</th>\n",
       "      <th>AgeBuckets_65_74</th>\n",
       "      <th>AgeBuckets_75_plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  SibSp  Parch  Sex_female  Sex_male  Embarked_C  \\\n",
       "0         0       3      1      0           0         1           0   \n",
       "1         1       1      1      0           1         0           1   \n",
       "2         1       3      0      0           1         0           0   \n",
       "3         1       1      1      0           1         0           0   \n",
       "4         0       3      0      0           0         1           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  AgeBuckets_0_17  AgeBuckets_18_24  \\\n",
       "0           0           1                0                 1   \n",
       "1           0           0                0                 0   \n",
       "2           0           1                0                 0   \n",
       "3           0           1                0                 0   \n",
       "4           0           1                0                 0   \n",
       "\n",
       "   AgeBuckets_25_34  AgeBuckets_35_44  AgeBuckets_45_54  AgeBuckets_55_64  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 1                 0                 0   \n",
       "2                 1                 0                 0                 0   \n",
       "3                 0                 1                 0                 0   \n",
       "4                 0                 1                 0                 0   \n",
       "\n",
       "   AgeBuckets_65_74  AgeBuckets_75_plus  \n",
       "0                 0                   0  \n",
       "1                 0                   0  \n",
       "2                 0                   0  \n",
       "3                 0                   0  \n",
       "4                 0                   0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[['Pclass', 'SibSp', 'Parch', 'Sex_female', 'Sex_male',\n",
    "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'AgeBuckets_0_17',\n",
    "       'AgeBuckets_18_24', 'AgeBuckets_25_34', 'AgeBuckets_35_44',\n",
    "       'AgeBuckets_45_54', 'AgeBuckets_55_64', 'AgeBuckets_65_74',\n",
    "       'AgeBuckets_75_plus']])\n",
    "Y = np.array(df[['Survived']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 [==============================] - 0s 849us/step - loss: 0.7505 - accuracy: 0.5365\n",
      "Epoch 2/150\n",
      "72/72 [==============================] - 0s 870us/step - loss: 0.5764 - accuracy: 0.6952\n",
      "Epoch 3/150\n",
      "72/72 [==============================] - 0s 841us/step - loss: 0.5363 - accuracy: 0.7486\n",
      "Epoch 4/150\n",
      "72/72 [==============================] - 0s 979us/step - loss: 0.5100 - accuracy: 0.7697\n",
      "Epoch 5/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7809\n",
      "Epoch 6/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7823\n",
      "Epoch 7/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7865\n",
      "Epoch 8/150\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.4633 - accuracy: 0.7992\n",
      "Epoch 9/150\n",
      "72/72 [==============================] - 0s 957us/step - loss: 0.4558 - accuracy: 0.7949\n",
      "Epoch 10/150\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.4493 - accuracy: 0.8020\n",
      "Epoch 11/150\n",
      "72/72 [==============================] - 0s 984us/step - loss: 0.4432 - accuracy: 0.7949\n",
      "Epoch 12/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8006\n",
      "Epoch 13/150\n",
      "72/72 [==============================] - 0s 958us/step - loss: 0.4347 - accuracy: 0.8048\n",
      "Epoch 14/150\n",
      "72/72 [==============================] - 0s 936us/step - loss: 0.4309 - accuracy: 0.8034\n",
      "Epoch 15/150\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.4298 - accuracy: 0.8076\n",
      "Epoch 16/150\n",
      "72/72 [==============================] - 0s 818us/step - loss: 0.4250 - accuracy: 0.8118\n",
      "Epoch 17/150\n",
      "72/72 [==============================] - 0s 920us/step - loss: 0.4227 - accuracy: 0.8104\n",
      "Epoch 18/150\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.4207 - accuracy: 0.8188\n",
      "Epoch 19/150\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.4184 - accuracy: 0.8160\n",
      "Epoch 20/150\n",
      "72/72 [==============================] - 0s 995us/step - loss: 0.4158 - accuracy: 0.8146\n",
      "Epoch 21/150\n",
      "72/72 [==============================] - 0s 993us/step - loss: 0.4141 - accuracy: 0.8216\n",
      "Epoch 22/150\n",
      "72/72 [==============================] - 0s 985us/step - loss: 0.4136 - accuracy: 0.8188\n",
      "Epoch 23/150\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.4117 - accuracy: 0.8244\n",
      "Epoch 24/150\n",
      "72/72 [==============================] - 0s 952us/step - loss: 0.4100 - accuracy: 0.8329\n",
      "Epoch 25/150\n",
      "72/72 [==============================] - 0s 929us/step - loss: 0.4080 - accuracy: 0.8272\n",
      "Epoch 26/150\n",
      "72/72 [==============================] - 0s 870us/step - loss: 0.4107 - accuracy: 0.8216\n",
      "Epoch 27/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8258\n",
      "Epoch 28/150\n",
      "72/72 [==============================] - 0s 948us/step - loss: 0.4073 - accuracy: 0.8315\n",
      "Epoch 29/150\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.4040 - accuracy: 0.8357\n",
      "Epoch 30/150\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.4023 - accuracy: 0.8343\n",
      "Epoch 31/150\n",
      "72/72 [==============================] - 0s 836us/step - loss: 0.4032 - accuracy: 0.8371\n",
      "Epoch 32/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8329\n",
      "Epoch 33/150\n",
      "72/72 [==============================] - 0s 972us/step - loss: 0.4016 - accuracy: 0.8343\n",
      "Epoch 34/150\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.4002 - accuracy: 0.8399\n",
      "Epoch 35/150\n",
      "72/72 [==============================] - 0s 923us/step - loss: 0.3990 - accuracy: 0.8385\n",
      "Epoch 36/150\n",
      "72/72 [==============================] - 0s 887us/step - loss: 0.3996 - accuracy: 0.8315\n",
      "Epoch 37/150\n",
      "72/72 [==============================] - 0s 900us/step - loss: 0.3988 - accuracy: 0.8357\n",
      "Epoch 38/150\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.3986 - accuracy: 0.8272\n",
      "Epoch 39/150\n",
      "72/72 [==============================] - 0s 938us/step - loss: 0.3972 - accuracy: 0.8371\n",
      "Epoch 40/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8343\n",
      "Epoch 41/150\n",
      "72/72 [==============================] - 0s 997us/step - loss: 0.3979 - accuracy: 0.8371\n",
      "Epoch 42/150\n",
      "72/72 [==============================] - 0s 949us/step - loss: 0.3969 - accuracy: 0.8385\n",
      "Epoch 43/150\n",
      "72/72 [==============================] - 0s 996us/step - loss: 0.3952 - accuracy: 0.8371\n",
      "Epoch 44/150\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.3959 - accuracy: 0.8399\n",
      "Epoch 45/150\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.3954 - accuracy: 0.8357\n",
      "Epoch 46/150\n",
      "72/72 [==============================] - 0s 977us/step - loss: 0.3939 - accuracy: 0.8357\n",
      "Epoch 47/150\n",
      "72/72 [==============================] - 0s 974us/step - loss: 0.3939 - accuracy: 0.8399\n",
      "Epoch 48/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8385\n",
      "Epoch 49/150\n",
      "72/72 [==============================] - 0s 935us/step - loss: 0.3925 - accuracy: 0.8399\n",
      "Epoch 50/150\n",
      "72/72 [==============================] - 0s 958us/step - loss: 0.3948 - accuracy: 0.8287\n",
      "Epoch 51/150\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.3932 - accuracy: 0.8343\n",
      "Epoch 52/150\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.3921 - accuracy: 0.8399\n",
      "Epoch 53/150\n",
      "72/72 [==============================] - 0s 933us/step - loss: 0.3947 - accuracy: 0.8315\n",
      "Epoch 54/150\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.3934 - accuracy: 0.8301\n",
      "Epoch 55/150\n",
      "72/72 [==============================] - 0s 914us/step - loss: 0.3919 - accuracy: 0.8329\n",
      "Epoch 56/150\n",
      "72/72 [==============================] - 0s 907us/step - loss: 0.3924 - accuracy: 0.8343\n",
      "Epoch 57/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8357\n",
      "Epoch 58/150\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3910 - accuracy: 0.8343\n",
      "Epoch 59/150\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.3891 - accuracy: 0.8315\n",
      "Epoch 60/150\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.3916 - accuracy: 0.8343\n",
      "Epoch 61/150\n",
      "72/72 [==============================] - 0s 911us/step - loss: 0.3888 - accuracy: 0.8413\n",
      "Epoch 62/150\n",
      "72/72 [==============================] - 0s 944us/step - loss: 0.3871 - accuracy: 0.8357\n",
      "Epoch 63/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8413\n",
      "Epoch 64/150\n",
      "72/72 [==============================] - 0s 862us/step - loss: 0.3890 - accuracy: 0.8315\n",
      "Epoch 65/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3870 - accuracy: 0.8329\n",
      "Epoch 66/150\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3889 - accuracy: 0.8371\n",
      "Epoch 67/150\n",
      "72/72 [==============================] - 0s 689us/step - loss: 0.3859 - accuracy: 0.8385\n",
      "Epoch 68/150\n",
      "72/72 [==============================] - 0s 724us/step - loss: 0.3851 - accuracy: 0.8385\n",
      "Epoch 69/150\n",
      "72/72 [==============================] - 0s 819us/step - loss: 0.3865 - accuracy: 0.8343\n",
      "Epoch 70/150\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.3869 - accuracy: 0.8441\n",
      "Epoch 71/150\n",
      "72/72 [==============================] - 0s 657us/step - loss: 0.3846 - accuracy: 0.8301\n",
      "Epoch 72/150\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.3856 - accuracy: 0.8371\n",
      "Epoch 73/150\n",
      "72/72 [==============================] - 0s 665us/step - loss: 0.3848 - accuracy: 0.8427\n",
      "Epoch 74/150\n",
      "72/72 [==============================] - 0s 694us/step - loss: 0.3828 - accuracy: 0.8371\n",
      "Epoch 75/150\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.3855 - accuracy: 0.8413\n",
      "Epoch 76/150\n",
      "72/72 [==============================] - 0s 627us/step - loss: 0.3826 - accuracy: 0.8385\n",
      "Epoch 77/150\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.3834 - accuracy: 0.8287\n",
      "Epoch 78/150\n",
      "72/72 [==============================] - 0s 598us/step - loss: 0.3814 - accuracy: 0.8329\n",
      "Epoch 79/150\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.3808 - accuracy: 0.8441\n",
      "Epoch 80/150\n",
      "72/72 [==============================] - 0s 614us/step - loss: 0.3820 - accuracy: 0.8399\n",
      "Epoch 81/150\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.3810 - accuracy: 0.8399\n",
      "Epoch 82/150\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.3798 - accuracy: 0.8329\n",
      "Epoch 83/150\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.3812 - accuracy: 0.8343\n",
      "Epoch 84/150\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.3796 - accuracy: 0.8385\n",
      "Epoch 85/150\n",
      "72/72 [==============================] - 0s 607us/step - loss: 0.3822 - accuracy: 0.8357\n",
      "Epoch 86/150\n",
      "72/72 [==============================] - 0s 627us/step - loss: 0.3792 - accuracy: 0.8371\n",
      "Epoch 87/150\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.3804 - accuracy: 0.8371\n",
      "Epoch 88/150\n",
      "72/72 [==============================] - 0s 605us/step - loss: 0.3801 - accuracy: 0.8413\n",
      "Epoch 89/150\n",
      "72/72 [==============================] - 0s 605us/step - loss: 0.3778 - accuracy: 0.8399\n",
      "Epoch 90/150\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.3780 - accuracy: 0.8455\n",
      "Epoch 91/150\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.3783 - accuracy: 0.8315\n",
      "Epoch 92/150\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.3760 - accuracy: 0.8343\n",
      "Epoch 93/150\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.3770 - accuracy: 0.8413\n",
      "Epoch 94/150\n",
      "72/72 [==============================] - 0s 615us/step - loss: 0.3787 - accuracy: 0.8301\n",
      "Epoch 95/150\n",
      "72/72 [==============================] - 0s 600us/step - loss: 0.3764 - accuracy: 0.8371\n",
      "Epoch 96/150\n",
      "72/72 [==============================] - 0s 621us/step - loss: 0.3750 - accuracy: 0.8427\n",
      "Epoch 97/150\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.3738 - accuracy: 0.8371\n",
      "Epoch 98/150\n",
      "72/72 [==============================] - 0s 607us/step - loss: 0.3747 - accuracy: 0.8399\n",
      "Epoch 99/150\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.3743 - accuracy: 0.8385\n",
      "Epoch 100/150\n",
      "72/72 [==============================] - 0s 614us/step - loss: 0.3750 - accuracy: 0.8371\n",
      "Epoch 101/150\n",
      "72/72 [==============================] - 0s 645us/step - loss: 0.3738 - accuracy: 0.8329\n",
      "Epoch 102/150\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.3722 - accuracy: 0.8385\n",
      "Epoch 103/150\n",
      "72/72 [==============================] - 0s 594us/step - loss: 0.3741 - accuracy: 0.8385\n",
      "Epoch 104/150\n",
      "72/72 [==============================] - 0s 605us/step - loss: 0.3737 - accuracy: 0.8357\n",
      "Epoch 105/150\n",
      "72/72 [==============================] - 0s 617us/step - loss: 0.3725 - accuracy: 0.8385\n",
      "Epoch 106/150\n",
      "72/72 [==============================] - 0s 592us/step - loss: 0.3709 - accuracy: 0.8427\n",
      "Epoch 107/150\n",
      "72/72 [==============================] - 0s 591us/step - loss: 0.3701 - accuracy: 0.8385\n",
      "Epoch 108/150\n",
      "72/72 [==============================] - 0s 594us/step - loss: 0.3716 - accuracy: 0.8343\n",
      "Epoch 109/150\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.3708 - accuracy: 0.8427\n",
      "Epoch 110/150\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.3701 - accuracy: 0.8399\n",
      "Epoch 111/150\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.3696 - accuracy: 0.8371\n",
      "Epoch 112/150\n",
      "72/72 [==============================] - 0s 610us/step - loss: 0.3702 - accuracy: 0.8371\n",
      "Epoch 113/150\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.3697 - accuracy: 0.8329\n",
      "Epoch 114/150\n",
      "72/72 [==============================] - 0s 594us/step - loss: 0.3696 - accuracy: 0.8441\n",
      "Epoch 115/150\n",
      "72/72 [==============================] - 0s 598us/step - loss: 0.3706 - accuracy: 0.8455\n",
      "Epoch 116/150\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.3684 - accuracy: 0.8497\n",
      "Epoch 117/150\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.3694 - accuracy: 0.8399\n",
      "Epoch 118/150\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.3689 - accuracy: 0.8441\n",
      "Epoch 119/150\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.3668 - accuracy: 0.8399\n",
      "Epoch 120/150\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.3696 - accuracy: 0.8413\n",
      "Epoch 121/150\n",
      "72/72 [==============================] - 0s 610us/step - loss: 0.3669 - accuracy: 0.8371\n",
      "Epoch 122/150\n",
      "72/72 [==============================] - 0s 868us/step - loss: 0.3692 - accuracy: 0.8427\n",
      "Epoch 123/150\n",
      "72/72 [==============================] - 0s 643us/step - loss: 0.3665 - accuracy: 0.8469\n",
      "Epoch 124/150\n",
      "72/72 [==============================] - 0s 707us/step - loss: 0.3671 - accuracy: 0.8427\n",
      "Epoch 125/150\n",
      "72/72 [==============================] - 0s 645us/step - loss: 0.3672 - accuracy: 0.8343\n",
      "Epoch 126/150\n",
      "72/72 [==============================] - 0s 607us/step - loss: 0.3661 - accuracy: 0.8483\n",
      "Epoch 127/150\n",
      "72/72 [==============================] - 0s 638us/step - loss: 0.3676 - accuracy: 0.8399\n",
      "Epoch 128/150\n",
      "72/72 [==============================] - 0s 598us/step - loss: 0.3668 - accuracy: 0.8385\n",
      "Epoch 129/150\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.3659 - accuracy: 0.8427\n",
      "Epoch 130/150\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.3663 - accuracy: 0.8497\n",
      "Epoch 131/150\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.3647 - accuracy: 0.8441\n",
      "Epoch 132/150\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.3653 - accuracy: 0.8511\n",
      "Epoch 133/150\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.3626 - accuracy: 0.8427\n",
      "Epoch 134/150\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.3667 - accuracy: 0.8441\n",
      "Epoch 135/150\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.3637 - accuracy: 0.8441\n",
      "Epoch 136/150\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.3647 - accuracy: 0.8413\n",
      "Epoch 137/150\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.3682 - accuracy: 0.8441\n",
      "Epoch 138/150\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.3646 - accuracy: 0.8371\n",
      "Epoch 139/150\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.3628 - accuracy: 0.8497\n",
      "Epoch 140/150\n",
      "72/72 [==============================] - 0s 624us/step - loss: 0.3645 - accuracy: 0.8469\n",
      "Epoch 141/150\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.3629 - accuracy: 0.8441\n",
      "Epoch 142/150\n",
      "72/72 [==============================] - 0s 989us/step - loss: 0.3638 - accuracy: 0.8399\n",
      "Epoch 143/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8427\n",
      "Epoch 144/150\n",
      "72/72 [==============================] - 0s 737us/step - loss: 0.3647 - accuracy: 0.8497\n",
      "Epoch 145/150\n",
      "72/72 [==============================] - 0s 639us/step - loss: 0.3622 - accuracy: 0.8455\n",
      "Epoch 146/150\n",
      "72/72 [==============================] - 0s 628us/step - loss: 0.3646 - accuracy: 0.8399\n",
      "Epoch 147/150\n",
      "72/72 [==============================] - 0s 671us/step - loss: 0.3642 - accuracy: 0.8441\n",
      "Epoch 148/150\n",
      "72/72 [==============================] - 0s 874us/step - loss: 0.3631 - accuracy: 0.8427\n",
      "Epoch 149/150\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.3642 - accuracy: 0.8497\n",
      "Epoch 150/150\n",
      "72/72 [==============================] - 0s 634us/step - loss: 0.3617 - accuracy: 0.8483\n",
      "23/23 [==============================] - 0s 618us/step - loss: 0.3577 - accuracy: 0.8483\n",
      "Accuracy: 84.83\n"
     ]
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, Y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/lilymartin/DEVOPS/testing_python_docker/app/model/20200823_titantic_m1.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
