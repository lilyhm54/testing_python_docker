{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Practice Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/lilymartin/DEVOPS/testing_python_docker/app/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns = ['Cabin', 'Name', 'Ticket']):\n",
    "    \"\"\"\n",
    "    remove unwanted columns\n",
    "    \"\"\"\n",
    "    cols = [x for x in list(df.columns) if x not in columns]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nan(df):\n",
    "    \"\"\"\n",
    "    Checking df for any rows with NaN\n",
    "    \"\"\"\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_buckets(df):\n",
    "    \"\"\"\n",
    "    Sort age column into age buckets\n",
    "    \"\"\"\n",
    "    age_col = 'Age'\n",
    "    df['AgeBucket'] = pd.qcut(df['Age'], q=8) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_buckets(df):\n",
    "    \"\"\"\n",
    "    Sort fares into buckets\n",
    "    \"\"\"\n",
    "    fare_col = 'Fare'\n",
    "    df['FareBucket'] = pd.qcut(df[fare_col], q=4)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encoding(df):\n",
    "    \"\"\"\n",
    "    Hot encoding spefic columns \n",
    "    \"\"\"\n",
    "    cols = [x for x in list(df.columns) if x in ['Sex', 'Embarked', 'AgeBucket', 'FareBucket']]\n",
    "    \n",
    "    for x in cols: \n",
    "        dummies = pd.get_dummies(df[x], x)\n",
    "        df = pd.concat([df.drop(x, axis=1), dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning \n",
    "df = pd.read_csv('/Users/lilymartin/DEVOPS/testing_python_docker/app/data/train.csv')\n",
    "df = remove_columns(df, ['Cabin', 'Name', 'Ticket'])\n",
    "df = check_for_nan(df)\n",
    "df = age_buckets(df)\n",
    "df = fare_buckets(df)\n",
    "df = hot_encoding(df)\n",
    "df = remove_columns(df, ['Age', 'Fare', 'PassengerId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=20, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = [x for x in list(df.columns) if x != 'Survived']\n",
    "\n",
    "X = np.array(df[X_cols])\n",
    "Y = np.array(df[['Survived']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.7781 - accuracy: 0.4874\n",
      "Epoch 2/150\n",
      "72/72 [==============================] - 0s 875us/step - loss: 0.6194 - accuracy: 0.7219\n",
      "Epoch 3/150\n",
      "72/72 [==============================] - 0s 840us/step - loss: 0.5626 - accuracy: 0.7247\n",
      "Epoch 4/150\n",
      "72/72 [==============================] - 0s 883us/step - loss: 0.5164 - accuracy: 0.7486\n",
      "Epoch 5/150\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.4813 - accuracy: 0.7851\n",
      "Epoch 6/150\n",
      "72/72 [==============================] - 0s 972us/step - loss: 0.4603 - accuracy: 0.7837\n",
      "Epoch 7/150\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.4487 - accuracy: 0.7823\n",
      "Epoch 8/150\n",
      "72/72 [==============================] - 0s 948us/step - loss: 0.4434 - accuracy: 0.7907\n",
      "Epoch 9/150\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.4395 - accuracy: 0.7992\n",
      "Epoch 10/150\n",
      "72/72 [==============================] - 0s 928us/step - loss: 0.4341 - accuracy: 0.7978\n",
      "Epoch 11/150\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.4345 - accuracy: 0.8076\n",
      "Epoch 12/150\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.4300 - accuracy: 0.8104\n",
      "Epoch 13/150\n",
      "72/72 [==============================] - 0s 867us/step - loss: 0.4277 - accuracy: 0.8188\n",
      "Epoch 14/150\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.4267 - accuracy: 0.8090\n",
      "Epoch 15/150\n",
      "72/72 [==============================] - 0s 851us/step - loss: 0.4251 - accuracy: 0.8132\n",
      "Epoch 16/150\n",
      "72/72 [==============================] - 0s 833us/step - loss: 0.4222 - accuracy: 0.8216\n",
      "Epoch 17/150\n",
      "72/72 [==============================] - 0s 880us/step - loss: 0.4211 - accuracy: 0.8244\n",
      "Epoch 18/150\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.4186 - accuracy: 0.8230\n",
      "Epoch 19/150\n",
      "72/72 [==============================] - 0s 951us/step - loss: 0.4183 - accuracy: 0.8287\n",
      "Epoch 20/150\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.4157 - accuracy: 0.8287\n",
      "Epoch 21/150\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.4160 - accuracy: 0.8230\n",
      "Epoch 22/150\n",
      "72/72 [==============================] - 0s 875us/step - loss: 0.4121 - accuracy: 0.8272\n",
      "Epoch 23/150\n",
      "72/72 [==============================] - 0s 825us/step - loss: 0.4115 - accuracy: 0.8272\n",
      "Epoch 24/150\n",
      "72/72 [==============================] - 0s 820us/step - loss: 0.4101 - accuracy: 0.8301\n",
      "Epoch 25/150\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.4098 - accuracy: 0.8329\n",
      "Epoch 26/150\n",
      "72/72 [==============================] - 0s 813us/step - loss: 0.4066 - accuracy: 0.8272\n",
      "Epoch 27/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8329\n",
      "Epoch 28/150\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.4059 - accuracy: 0.8258\n",
      "Epoch 29/150\n",
      "72/72 [==============================] - 0s 833us/step - loss: 0.4039 - accuracy: 0.8329\n",
      "Epoch 30/150\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.4023 - accuracy: 0.8371\n",
      "Epoch 31/150\n",
      "72/72 [==============================] - 0s 889us/step - loss: 0.4000 - accuracy: 0.8357\n",
      "Epoch 32/150\n",
      "72/72 [==============================] - 0s 905us/step - loss: 0.3991 - accuracy: 0.8371\n",
      "Epoch 33/150\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.4040 - accuracy: 0.8287\n",
      "Epoch 34/150\n",
      "72/72 [==============================] - 0s 908us/step - loss: 0.3982 - accuracy: 0.8301\n",
      "Epoch 35/150\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.3948 - accuracy: 0.8258\n",
      "Epoch 36/150\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.3933 - accuracy: 0.8329\n",
      "Epoch 37/150\n",
      "72/72 [==============================] - 0s 856us/step - loss: 0.3925 - accuracy: 0.8343\n",
      "Epoch 38/150\n",
      "72/72 [==============================] - 0s 815us/step - loss: 0.3919 - accuracy: 0.8329\n",
      "Epoch 39/150\n",
      "72/72 [==============================] - 0s 824us/step - loss: 0.3900 - accuracy: 0.8483\n",
      "Epoch 40/150\n",
      "72/72 [==============================] - 0s 857us/step - loss: 0.3912 - accuracy: 0.8357\n",
      "Epoch 41/150\n",
      "72/72 [==============================] - 0s 886us/step - loss: 0.3873 - accuracy: 0.8413\n",
      "Epoch 42/150\n",
      "72/72 [==============================] - 0s 835us/step - loss: 0.3861 - accuracy: 0.8469\n",
      "Epoch 43/150\n",
      "72/72 [==============================] - 0s 893us/step - loss: 0.3871 - accuracy: 0.8399\n",
      "Epoch 44/150\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.3848 - accuracy: 0.8483\n",
      "Epoch 45/150\n",
      "72/72 [==============================] - 0s 936us/step - loss: 0.3836 - accuracy: 0.8399\n",
      "Epoch 46/150\n",
      "72/72 [==============================] - 0s 883us/step - loss: 0.3814 - accuracy: 0.8441\n",
      "Epoch 47/150\n",
      "72/72 [==============================] - 0s 878us/step - loss: 0.3821 - accuracy: 0.8441\n",
      "Epoch 48/150\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.3779 - accuracy: 0.8497\n",
      "Epoch 49/150\n",
      "72/72 [==============================] - 0s 894us/step - loss: 0.3778 - accuracy: 0.8385\n",
      "Epoch 50/150\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.3815 - accuracy: 0.8371\n",
      "Epoch 51/150\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.3766 - accuracy: 0.8469\n",
      "Epoch 52/150\n",
      "72/72 [==============================] - 0s 861us/step - loss: 0.3748 - accuracy: 0.8483\n",
      "Epoch 53/150\n",
      "72/72 [==============================] - 0s 963us/step - loss: 0.3738 - accuracy: 0.8399\n",
      "Epoch 54/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8441\n",
      "Epoch 55/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8371\n",
      "Epoch 56/150\n",
      "72/72 [==============================] - 0s 975us/step - loss: 0.3715 - accuracy: 0.8511\n",
      "Epoch 57/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8469\n",
      "Epoch 58/150\n",
      "72/72 [==============================] - 0s 947us/step - loss: 0.3687 - accuracy: 0.8441\n",
      "Epoch 59/150\n",
      "72/72 [==============================] - 0s 885us/step - loss: 0.3663 - accuracy: 0.8413\n",
      "Epoch 60/150\n",
      "72/72 [==============================] - 0s 907us/step - loss: 0.3660 - accuracy: 0.8441\n",
      "Epoch 61/150\n",
      "72/72 [==============================] - 0s 894us/step - loss: 0.3671 - accuracy: 0.8455\n",
      "Epoch 62/150\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.3661 - accuracy: 0.8483\n",
      "Epoch 63/150\n",
      "72/72 [==============================] - 0s 850us/step - loss: 0.3630 - accuracy: 0.8483\n",
      "Epoch 64/150\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.3629 - accuracy: 0.8497\n",
      "Epoch 65/150\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.3651 - accuracy: 0.8497\n",
      "Epoch 66/150\n",
      "72/72 [==============================] - 0s 957us/step - loss: 0.3624 - accuracy: 0.8497\n",
      "Epoch 67/150\n",
      "72/72 [==============================] - 0s 986us/step - loss: 0.3602 - accuracy: 0.8553\n",
      "Epoch 68/150\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.3603 - accuracy: 0.8441\n",
      "Epoch 69/150\n",
      "72/72 [==============================] - 0s 973us/step - loss: 0.3606 - accuracy: 0.8455\n",
      "Epoch 70/150\n",
      "72/72 [==============================] - 0s 864us/step - loss: 0.3553 - accuracy: 0.8539\n",
      "Epoch 71/150\n",
      "72/72 [==============================] - 0s 861us/step - loss: 0.3552 - accuracy: 0.8567\n",
      "Epoch 72/150\n",
      "72/72 [==============================] - 0s 854us/step - loss: 0.3523 - accuracy: 0.8567\n",
      "Epoch 73/150\n",
      "72/72 [==============================] - 0s 848us/step - loss: 0.3525 - accuracy: 0.8539\n",
      "Epoch 74/150\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.3518 - accuracy: 0.8539\n",
      "Epoch 75/150\n",
      "72/72 [==============================] - 0s 869us/step - loss: 0.3524 - accuracy: 0.8539\n",
      "Epoch 76/150\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.3493 - accuracy: 0.8483\n",
      "Epoch 77/150\n",
      "72/72 [==============================] - 0s 875us/step - loss: 0.3485 - accuracy: 0.8567\n",
      "Epoch 78/150\n",
      "72/72 [==============================] - 0s 863us/step - loss: 0.3462 - accuracy: 0.8567\n",
      "Epoch 79/150\n",
      "72/72 [==============================] - 0s 958us/step - loss: 0.3493 - accuracy: 0.8567\n",
      "Epoch 80/150\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.3454 - accuracy: 0.8567\n",
      "Epoch 81/150\n",
      "72/72 [==============================] - 0s 896us/step - loss: 0.3447 - accuracy: 0.8511\n",
      "Epoch 82/150\n",
      "72/72 [==============================] - 0s 882us/step - loss: 0.3463 - accuracy: 0.8567\n",
      "Epoch 83/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8567\n",
      "Epoch 84/150\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.3416 - accuracy: 0.8581\n",
      "Epoch 85/150\n",
      "72/72 [==============================] - 0s 988us/step - loss: 0.3437 - accuracy: 0.8553\n",
      "Epoch 86/150\n",
      "72/72 [==============================] - 0s 860us/step - loss: 0.3442 - accuracy: 0.8539\n",
      "Epoch 87/150\n",
      "72/72 [==============================] - 0s 876us/step - loss: 0.3416 - accuracy: 0.8469\n",
      "Epoch 88/150\n",
      "72/72 [==============================] - 0s 843us/step - loss: 0.3398 - accuracy: 0.8581\n",
      "Epoch 89/150\n",
      "72/72 [==============================] - 0s 889us/step - loss: 0.3395 - accuracy: 0.8581\n",
      "Epoch 90/150\n",
      "72/72 [==============================] - 0s 845us/step - loss: 0.3392 - accuracy: 0.8596\n",
      "Epoch 91/150\n",
      "72/72 [==============================] - 0s 894us/step - loss: 0.3404 - accuracy: 0.8525\n",
      "Epoch 92/150\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.3361 - accuracy: 0.8610\n",
      "Epoch 93/150\n",
      "72/72 [==============================] - 0s 937us/step - loss: 0.3368 - accuracy: 0.8539\n",
      "Epoch 94/150\n",
      "72/72 [==============================] - 0s 821us/step - loss: 0.3388 - accuracy: 0.8596\n",
      "Epoch 95/150\n",
      "72/72 [==============================] - 0s 874us/step - loss: 0.3369 - accuracy: 0.8596\n",
      "Epoch 96/150\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.3359 - accuracy: 0.8596\n",
      "Epoch 97/150\n",
      "72/72 [==============================] - 0s 874us/step - loss: 0.3351 - accuracy: 0.8610\n",
      "Epoch 98/150\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.3367 - accuracy: 0.8567\n",
      "Epoch 99/150\n",
      "72/72 [==============================] - 0s 882us/step - loss: 0.3353 - accuracy: 0.8581\n",
      "Epoch 100/150\n",
      "72/72 [==============================] - 0s 891us/step - loss: 0.3335 - accuracy: 0.8567\n",
      "Epoch 101/150\n",
      "72/72 [==============================] - 0s 919us/step - loss: 0.3346 - accuracy: 0.8624\n",
      "Epoch 102/150\n",
      "72/72 [==============================] - 0s 849us/step - loss: 0.3359 - accuracy: 0.8581\n",
      "Epoch 103/150\n",
      "72/72 [==============================] - 0s 844us/step - loss: 0.3323 - accuracy: 0.8581\n",
      "Epoch 104/150\n",
      "72/72 [==============================] - 0s 894us/step - loss: 0.3317 - accuracy: 0.8539\n",
      "Epoch 105/150\n",
      "72/72 [==============================] - 0s 855us/step - loss: 0.3318 - accuracy: 0.8680\n",
      "Epoch 106/150\n",
      "72/72 [==============================] - 0s 897us/step - loss: 0.3324 - accuracy: 0.8553\n",
      "Epoch 107/150\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.3313 - accuracy: 0.8581\n",
      "Epoch 108/150\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.3327 - accuracy: 0.8567\n",
      "Epoch 109/150\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.3303 - accuracy: 0.8624\n",
      "Epoch 110/150\n",
      "72/72 [==============================] - 0s 877us/step - loss: 0.3315 - accuracy: 0.8610\n",
      "Epoch 111/150\n",
      "72/72 [==============================] - 0s 983us/step - loss: 0.3305 - accuracy: 0.8610\n",
      "Epoch 112/150\n",
      "72/72 [==============================] - 0s 847us/step - loss: 0.3331 - accuracy: 0.8610\n",
      "Epoch 113/150\n",
      "72/72 [==============================] - 0s 881us/step - loss: 0.3292 - accuracy: 0.8610\n",
      "Epoch 114/150\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.3278 - accuracy: 0.8596\n",
      "Epoch 115/150\n",
      "72/72 [==============================] - 0s 866us/step - loss: 0.3268 - accuracy: 0.8638\n",
      "Epoch 116/150\n",
      "72/72 [==============================] - 0s 971us/step - loss: 0.3269 - accuracy: 0.8596\n",
      "Epoch 117/150\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.3285 - accuracy: 0.8539\n",
      "Epoch 118/150\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.3287 - accuracy: 0.8624\n",
      "Epoch 119/150\n",
      "72/72 [==============================] - 0s 856us/step - loss: 0.3254 - accuracy: 0.8666\n",
      "Epoch 120/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8581\n",
      "Epoch 121/150\n",
      "72/72 [==============================] - 0s 870us/step - loss: 0.3263 - accuracy: 0.8652\n",
      "Epoch 122/150\n",
      "72/72 [==============================] - 0s 924us/step - loss: 0.3245 - accuracy: 0.8638\n",
      "Epoch 123/150\n",
      "72/72 [==============================] - 0s 882us/step - loss: 0.3250 - accuracy: 0.8596\n",
      "Epoch 124/150\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.3242 - accuracy: 0.8596\n",
      "Epoch 125/150\n",
      "72/72 [==============================] - 0s 925us/step - loss: 0.3231 - accuracy: 0.8638\n",
      "Epoch 126/150\n",
      "72/72 [==============================] - 0s 872us/step - loss: 0.3222 - accuracy: 0.8666\n",
      "Epoch 127/150\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.3223 - accuracy: 0.8694\n",
      "Epoch 128/150\n",
      "72/72 [==============================] - 0s 884us/step - loss: 0.3252 - accuracy: 0.8596\n",
      "Epoch 129/150\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 0.8638\n",
      "Epoch 130/150\n",
      "72/72 [==============================] - 0s 975us/step - loss: 0.3200 - accuracy: 0.8624\n",
      "Epoch 131/150\n",
      "72/72 [==============================] - 0s 912us/step - loss: 0.3240 - accuracy: 0.8610\n",
      "Epoch 132/150\n",
      "72/72 [==============================] - 0s 958us/step - loss: 0.3207 - accuracy: 0.8610\n",
      "Epoch 133/150\n",
      "72/72 [==============================] - 0s 969us/step - loss: 0.3250 - accuracy: 0.8652\n",
      "Epoch 134/150\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.3197 - accuracy: 0.8680\n",
      "Epoch 135/150\n",
      "72/72 [==============================] - 0s 955us/step - loss: 0.3212 - accuracy: 0.8610\n",
      "Epoch 136/150\n",
      "72/72 [==============================] - 0s 978us/step - loss: 0.3204 - accuracy: 0.8680\n",
      "Epoch 137/150\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.3221 - accuracy: 0.8610\n",
      "Epoch 138/150\n",
      "72/72 [==============================] - 0s 946us/step - loss: 0.3175 - accuracy: 0.8666\n",
      "Epoch 139/150\n",
      "72/72 [==============================] - 0s 956us/step - loss: 0.3189 - accuracy: 0.8624\n",
      "Epoch 140/150\n",
      "72/72 [==============================] - 0s 892us/step - loss: 0.3175 - accuracy: 0.8652\n",
      "Epoch 141/150\n",
      "72/72 [==============================] - 0s 943us/step - loss: 0.3193 - accuracy: 0.8666\n",
      "Epoch 142/150\n",
      "72/72 [==============================] - 0s 980us/step - loss: 0.3192 - accuracy: 0.8610\n",
      "Epoch 143/150\n",
      "72/72 [==============================] - 0s 934us/step - loss: 0.3250 - accuracy: 0.8638\n",
      "Epoch 144/150\n",
      "72/72 [==============================] - 0s 891us/step - loss: 0.3187 - accuracy: 0.8652\n",
      "Epoch 145/150\n",
      "72/72 [==============================] - 0s 993us/step - loss: 0.3185 - accuracy: 0.8694\n",
      "Epoch 146/150\n",
      "72/72 [==============================] - 0s 950us/step - loss: 0.3182 - accuracy: 0.8694\n",
      "Epoch 147/150\n",
      "72/72 [==============================] - 0s 984us/step - loss: 0.3200 - accuracy: 0.8708\n",
      "Epoch 148/150\n",
      "72/72 [==============================] - 0s 926us/step - loss: 0.3160 - accuracy: 0.8736\n",
      "Epoch 149/150\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.3152 - accuracy: 0.8638\n",
      "Epoch 150/150\n",
      "72/72 [==============================] - 0s 965us/step - loss: 0.3169 - accuracy: 0.8694\n",
      "23/23 [==============================] - 0s 651us/step - loss: 0.3084 - accuracy: 0.8736\n",
      "Accuracy: 87.36\n"
     ]
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, Y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/lilymartin/DEVOPS/testing_python_docker/app/model/20200823_titanic_m1.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
